import time
from stable_baselines3 import PPO
from sim_env import K8sClusterEnv
import os

def train():
    print("ğŸ—ï¸  CrÃ©ation de l'environnement de simulation 5G (NexSlice)...")
    env = K8sClusterEnv()

    print("ğŸ§  Configuration de l'agent PPO (RÃ©seau de neurones [128, 128])...")
    model = PPO(
        "MlpPolicy", 
        env, 
        verbose=1, 
        learning_rate=0.0003,
        policy_kwargs=dict(net_arch=[128, 128])
    )

    print("ğŸ’ª DÃ©marrage de l'entraÃ®nement EXTENDED (300,000 steps)...")
    print("   (Cela va prendre ~2-3 minutes sur M4 Pro. Ferme Docker/OrbStack pour la vitesse !)")
    
    start_time = time.time()
    
    # On double le temps d'entraÃ®nement pour casser les biais et apprendre les compromis difficiles
    model.learn(total_timesteps=300000)
    
    end_time = time.time()
    duration = end_time - start_time

    print(f"âœ… EntraÃ®nement terminÃ© en {duration:.2f} secondes !")

    model_name = "scheduler_rl_brain"
    model.save(model_name)
    print(f"ğŸ’¾ Cerveau expert sauvegardÃ© sous '{model_name}.zip'")

if __name__ == "__main__":
    train()
